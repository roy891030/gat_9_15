# RunPods å®Œæ•´è¨“ç·´æŒ‡å—

## ğŸš€ å¿«é€Ÿé–‹å§‹

### Step 1: æ¸…ç†æ‰€æœ‰èˆŠçµæœ

```bash
cd /workspace/gat_9_15  # æˆ–ä½ çš„å°ˆæ¡ˆè·¯å¾‘

# æ¸…ç†æ‰€æœ‰èˆŠçš„çµæœã€artifactsã€åœ–è¡¨
bash clean_all_results.sh
```

**æ¸…ç†å…§å®¹ï¼š**
- âœ“ åœæ­¢æ‰€æœ‰æ­£åœ¨é‹è¡Œçš„è¨“ç·´é€²ç¨‹
- âœ“ åˆªé™¤æ‰€æœ‰ `gat_artifacts_*` ç›®éŒ„
- âœ“ åˆªé™¤æ‰€æœ‰ `results_*.txt` æª”æ¡ˆ
- âœ“ åˆªé™¤æ‰€æœ‰ `plots_*` ç›®éŒ„
- âœ“ åˆªé™¤æ‰€æœ‰ `train*.log` æª”æ¡ˆ

---

### Step 2: é¸æ“‡è¨“ç·´æ–¹å¼

#### æ–¹å¼ A: ä¸²è¡Œè¨“ç·´ï¼ˆæ¨è–¦ï¼Œç©©å®šï¼‰

```bash
bash run_all_models.sh
```

**ç‰¹é»ï¼š**
- âœ… ä¸€æ¬¡è¨“ç·´ä¸€å€‹æ¨¡å‹ï¼ˆç©©å®šï¼‰
- âœ… GPU è¨˜æ†¶é«”ä½¿ç”¨è¼ƒä½
- âœ… é©åˆ 16GB VRAMï¼ˆå¦‚ RTX 4090ï¼‰
- â±ï¸ è¨“ç·´æ™‚é–“è¼ƒé•·ï¼ˆç´„ 4-6 å°æ™‚ï¼‰

---

#### æ–¹å¼ B: ä¸¦è¡Œè¨“ç·´ï¼ˆæ›´å¿«ï¼Œéœ€è¦æ›´å¤š VRAMï¼‰

```bash
bash run_all_models_parallel.sh
```

**ç‰¹é»ï¼š**
- âš¡ åŒæ™‚è¨“ç·´å¤šå€‹æ¨¡å‹ï¼ˆæ›´å¿«ï¼‰
- âš ï¸ GPU è¨˜æ†¶é«”ä½¿ç”¨è¼ƒé«˜
- âœ… é©åˆ 24GB+ VRAMï¼ˆå¦‚ RTX 3090, A5000, A6000ï¼‰
- â±ï¸ è¨“ç·´æ™‚é–“è¼ƒçŸ­ï¼ˆç´„ 2-3 å°æ™‚ï¼‰

---

### Step 3: ç›£æ§è¨“ç·´é€²åº¦

#### æŸ¥çœ‹è¨“ç·´æ—¥èªŒ

```bash
# æŸ¥çœ‹æ‰€æœ‰è¨“ç·´æ—¥èªŒ
tail -f train_short.log     # çŸ­æœŸ DMFM
tail -f train_medium.log    # ä¸­æœŸ DMFM
tail -f train_long.log      # é•·æœŸ DMFM
tail -f train_gat.log       # GATRegressor

# åŒæ™‚æŸ¥çœ‹å¤šå€‹æ—¥èªŒ
tail -f train_*.log
```

#### ç›£æ§ GPU ä½¿ç”¨

```bash
# å¯¦æ™‚ç›£æ§ GPU
watch -n 1 nvidia-smi

# æˆ–ä½¿ç”¨ gpustatï¼ˆå¦‚æœå®‰è£ï¼‰
watch -n 1 gpustat
```

#### æª¢æŸ¥è¨“ç·´é€²ç¨‹

```bash
# æŸ¥çœ‹æ­£åœ¨é‹è¡Œçš„è¨“ç·´
ps aux | grep train

# æŸ¥çœ‹ç‰¹å®šé€²ç¨‹
ps aux | grep train_dmfm_wei2022
ps aux | grep train_gat_fixed
```

---

### Step 4: ç­‰å¾…è¨“ç·´å®Œæˆ

è¨“ç·´æœƒåœ¨èƒŒæ™¯åŸ·è¡Œï¼Œä½ å¯ä»¥ï¼š

1. **æ–·ç·šå¾Œç¹¼çºŒè¨“ç·´**ï¼ˆä½¿ç”¨ nohupï¼‰
2. **é—œé–‰çµ‚ç«¯æ©Ÿ**ï¼ˆè¨“ç·´ä»ç¹¼çºŒï¼‰
3. **ç¨å¾Œé‡æ–°é€£ç·š**æŸ¥çœ‹çµæœ

#### æª¢æŸ¥è¨“ç·´æ˜¯å¦å®Œæˆ

```bash
# æŸ¥çœ‹è¨“ç·´æ—¥èªŒæœ€å¾Œå¹¾è¡Œ
tail -20 train_short.log
tail -20 train_medium.log
tail -20 train_long.log
tail -20 train_gat.log

# å°‹æ‰¾ "è¨“ç·´å®Œæˆ" æˆ– "Early stopping"
grep "è¨“ç·´å®Œæˆ\|Early stopping\|å®Œæˆ" train_*.log
```

#### æª¢æŸ¥æ¨¡å‹æª”æ¡ˆ

```bash
# æŸ¥çœ‹æ˜¯å¦ç”Ÿæˆæ¨¡å‹æª”æ¡ˆ
ls -lh gat_artifacts_*/dmfm_wei2022_best.pt
ls -lh gat_artifacts_*/gat_regressor.pt
```

---

### Step 5: è¦–è¦ºåŒ–å’Œè©•ä¼°ï¼ˆè¨“ç·´å®Œæˆå¾Œï¼‰

```bash
# åŸ·è¡Œå¾Œè™•ç†è…³æœ¬
bash post_process_all.sh
```

**ç”Ÿæˆå…§å®¹ï¼š**
- âœ“ Factor Attention åˆ†æï¼ˆæ¯å€‹æ¨¡å‹ï¼‰
- âœ“ éšå±¤å¼ç‰¹å¾µåˆ†æï¼ˆæ¯å€‹æ¨¡å‹ï¼‰
- âœ“ ç¸½çµå ±å‘Šï¼ˆRESULTS_SUMMARY.mdï¼‰

---

## ğŸ“Š è¨“ç·´æ¨¡å‹æ¸…å–®

| æ¨¡å‹ | è³‡æ–™æœŸé–“ | Artifacts ç›®éŒ„ | è¨“ç·´æ—¥èªŒ | é æœŸæ™‚é–“ |
|------|---------|---------------|---------|---------|
| DMFM (çŸ­æœŸ) | 2019-2020 | gat_artifacts_short | train_short.log | 30-40 min |
| DMFM (ä¸­æœŸ) | 2019-2022 | gat_artifacts_medium | train_medium.log | 50-60 min |
| DMFM (é•·æœŸ) | 2019-2025 | gat_artifacts_long | train_long.log | 60-80 min |
| GATRegressor | 2019-2022 | gat_artifacts_gat | train_gat.log | 20-30 min |

**ç¸½è¨ˆï¼š** ç´„ 2.5-3.5 å°æ™‚ï¼ˆä¸²è¡Œï¼‰ï¼Œ1.5-2.5 å°æ™‚ï¼ˆä¸¦è¡Œï¼‰

---

## ğŸ” æŸ¥çœ‹çµæœ

### è¨“ç·´æŒ‡æ¨™

```bash
# æŸ¥çœ‹è¨“ç·´æ—¥èªŒä¸­çš„æœ€ä½³æŒ‡æ¨™
grep "best\|Best" train_*.log

# æŸ¥çœ‹ Early Stopping
grep "Early stopping" train_*.log
```

### Factor Attention åˆ†æ

```bash
# æŸ¥çœ‹çŸ­æœŸ DMFM çš„ Factor Attention
cat plots_short_attention/factor_attention_summary.txt

# æŸ¥çœ‹ä¸­æœŸ DMFM
cat plots_medium_attention/factor_attention_summary.txt

# æŸ¥çœ‹é•·æœŸ DMFM
cat plots_long_attention/factor_attention_summary.txt
```

### éšå±¤å¼ç‰¹å¾µåˆ†æ

```bash
# æŸ¥çœ‹çŸ­æœŸ DMFM çš„éšå±¤å¼ç‰¹å¾µæ•ˆæœ
cat plots_short_contexts/context_analysis_summary.txt

# æŸ¥çœ‹ä¸­æœŸ DMFM
cat plots_medium_contexts/context_analysis_summary.txt

# æŸ¥çœ‹é•·æœŸ DMFM
cat plots_long_contexts/context_analysis_summary.txt
```

### ç¸½çµå ±å‘Š

```bash
# æŸ¥çœ‹è‡ªå‹•ç”Ÿæˆçš„ç¸½çµå ±å‘Š
cat RESULTS_SUMMARY.md
```

---

## ğŸ“ ç”Ÿæˆçš„æª”æ¡ˆçµæ§‹

```
gat_9_15/
â”œâ”€â”€ è¨“ç·´æ—¥èªŒ
â”‚   â”œâ”€â”€ train_short.log
â”‚   â”œâ”€â”€ train_medium.log
â”‚   â”œâ”€â”€ train_long.log
â”‚   â””â”€â”€ train_gat.log
â”‚
â”œâ”€â”€ Artifactsï¼ˆæ¨¡å‹å’Œè³‡æ–™ï¼‰
â”‚   â”œâ”€â”€ artifacts_short|medium|long/  # ä¾è¦–çª—åˆ†çµ„
â”‚   â””â”€â”€ experiments/                  # run_core_experiments.sh ç”¢å‡ºçš„æŒ‡æ¨™èˆ‡åœ–è¡¨
â”‚
â”œâ”€â”€ ç¯„ä¾‹è¼¸å‡ºï¼ˆåªè®€åƒè€ƒï¼‰
â”‚   â””â”€â”€ examples/
â”‚       â”œâ”€â”€ artifacts/{covid_crash,rate_hike}/
â”‚       â””â”€â”€ plots/short|medium|long|covid_crash|rate_hike/{dmfm,gat}/
â”‚
â””â”€â”€ ç¸½çµå ±å‘Šï¼ˆè‹¥æœ‰ç”Ÿæˆï¼‰
    â””â”€â”€ RESULTS_SUMMARY.md
```

---

## âš ï¸ å¸¸è¦‹å•é¡Œ

### Q1: è¨“ç·´ä¸­æ–·æ€éº¼è¾¦ï¼Ÿ

**A:** ä½¿ç”¨ nohupï¼Œè¨“ç·´æœƒåœ¨èƒŒæ™¯æŒçºŒé€²è¡Œï¼š

```bash
# æª¢æŸ¥è¨“ç·´æ˜¯å¦é‚„åœ¨é‹è¡Œ
ps aux | grep train

# æŸ¥çœ‹è¨“ç·´æ—¥èªŒç¢ºèªé€²åº¦
tail -f train_short.log

# å¦‚æœçœŸçš„ä¸­æ–·ï¼Œé‡æ–°å•Ÿå‹•ç‰¹å®šæ¨¡å‹ï¼š
nohup python train_dmfm_wei2022.py \
  --artifact_dir gat_artifacts_short \
  --epochs 200 \
  --lr 1e-3 \
  --device cuda \
  > train_short.log 2>&1 &
```

---

### Q2: GPU è¨˜æ†¶é«”ä¸è¶³æ€éº¼è¾¦ï¼Ÿ

**A:** æ¸›å°‘ batch size æˆ–ä½¿ç”¨è¼ƒå°çš„ hidden_dimï¼š

```bash
# æ–¹æ³• 1: ä½¿ç”¨ä¸²è¡Œè¨“ç·´ï¼ˆä¸è¦ä¸¦è¡Œï¼‰
bash run_all_models.sh

# æ–¹æ³• 2: ä¿®æ”¹æ¨¡å‹åƒæ•¸ï¼ˆè¼ƒå°çš„ hidden_dimï¼‰
python train_dmfm_wei2022.py \
  --hidden_dim 32 \  # é è¨­ 64
  --device cuda \
  ...
```

---

### Q3: å¦‚ä½•åªè¨“ç·´ç‰¹å®šæ¨¡å‹ï¼Ÿ

**A:** æ‰‹å‹•åŸ·è¡Œç‰¹å®šæ­¥é©Ÿï¼š

```bash
# åªè¨“ç·´é•·æœŸ DMFM
python build_artifacts.py \
  --artifact_dir gat_artifacts_long \
  --start_date 2019-09-16 \
  --end_date 2025-09-12 \
  --horizon 5

nohup python train_dmfm_wei2022.py \
  --artifact_dir gat_artifacts_long \
  --epochs 200 \
  --device cuda \
  > train_long.log 2>&1 &

# è¨“ç·´å®Œæˆå¾Œ
python visualize_factor_attention.py \
  --artifact_dir gat_artifacts_long \
  --output_dir plots_long_attention

python analyze_contexts.py \
  --artifact_dir gat_artifacts_long \
  --output_dir plots_long_contexts
```

---

### Q4: å¦‚ä½•ä¸‹è¼‰çµæœåˆ°æœ¬åœ°ï¼Ÿ

**A:** ä½¿ç”¨ SCP æˆ– RunPods çš„æª”æ¡ˆç®¡ç†ï¼š

```bash
# æ‰“åŒ…æ‰€æœ‰çµæœ
tar -czf results.tar.gz \
  plots_*/ \
  gat_artifacts_*/dmfm_wei2022_best.pt \
  gat_artifacts_*/train_log_wei2022.txt \
  train_*.log \
  RESULTS_SUMMARY.md

# ç„¶å¾Œå¾ RunPods ä»‹é¢ä¸‹è¼‰ results.tar.gz
```

---

### Q5: è¨“ç·´å®Œæˆå¾Œå¦‚ä½•æ¯”è¼ƒæ¨¡å‹ï¼Ÿ

**A:** æŸ¥çœ‹ç¸½çµå ±å‘Šå’Œè¦–è¦ºåŒ–ï¼š

```bash
# 1. æŸ¥çœ‹ç¸½çµå ±å‘Š
cat RESULTS_SUMMARY.md

# 2. æ¯”è¼ƒ Factor Attentionï¼ˆå“ªäº›ç‰¹å¾µé‡è¦ï¼‰
diff plots_short_attention/factor_attention_summary.txt \
     plots_long_attention/factor_attention_summary.txt

# 3. æ¯”è¼ƒè¨“ç·´æ—¥èªŒï¼ˆæ”¶æ–‚é€Ÿåº¦ã€æœ€ä½³ ICï¼‰
grep "Best\|best" train_*.log

# 4. æ¯”è¼ƒéšå±¤å¼ç‰¹å¾µæ•ˆæœï¼ˆè®Šç•°æ•¸é™ä½ï¼‰
grep "è®Šç•°æ•¸é™ä½\|Variance reduction" plots_*/context_analysis_summary.txt
```

---

## ğŸ¯ å®Œæ•´åŸ·è¡Œæµç¨‹ï¼ˆç¸½çµï¼‰

```bash
# 1. æ¸…ç†èˆŠçµæœ
bash clean_all_results.sh

# 2. è¨“ç·´æ‰€æœ‰æ¨¡å‹ï¼ˆé¸ä¸€å€‹ï¼‰
bash run_all_models.sh              # ä¸²è¡Œï¼ˆç©©å®šï¼‰
# æˆ–
bash run_all_models_parallel.sh     # ä¸¦è¡Œï¼ˆæ›´å¿«ï¼‰

# 3. ç›£æ§è¨“ç·´
tail -f train_*.log
watch -n 1 nvidia-smi

# 4. è¨“ç·´å®Œæˆå¾Œï¼Œè¦–è¦ºåŒ–å’Œè©•ä¼°
bash post_process_all.sh

# 5. æŸ¥çœ‹çµæœ
cat RESULTS_SUMMARY.md
cat plots_*_attention/factor_attention_summary.txt
cat plots_*_contexts/context_analysis_summary.txt

# 6. ä¸‹è¼‰çµæœï¼ˆå¯é¸ï¼‰
tar -czf results.tar.gz plots_*/ *.md *.log
```

---

## ğŸ“ éœ€è¦å¹«åŠ©ï¼Ÿ

- æŸ¥çœ‹è¨“ç·´æ—¥èªŒï¼š`tail -f train_*.log`
- æŸ¥çœ‹ GPU ç‹€æ…‹ï¼š`nvidia-smi`
- æª¢æŸ¥é€²ç¨‹ï¼š`ps aux | grep train`
- æŸ¥çœ‹éŒ¯èª¤ï¼š`grep -i error train_*.log`

---

ç¥è¨“ç·´é †åˆ©ï¼ğŸ‰
