# å°ˆæ¡ˆè©³è¿°ï¼šåŸºæ–¼æ·±åº¦å¤šå› å­æ¨¡å‹çš„è‚¡ç¥¨é æ¸¬ç³»çµ±

## ğŸ¯ å°ˆæ¡ˆç›®æ¨™

é€™æ˜¯ä¸€å€‹**é‡åŒ–äº¤æ˜“ç ”ç©¶å°ˆæ¡ˆ**ï¼Œä½¿ç”¨æ·±åº¦å­¸ç¿’æŠ€è¡“é æ¸¬å°ç£è‚¡å¸‚çš„è‚¡ç¥¨å ±é…¬ç‡ï¼Œä¸¦å»ºç«‹æŠ•è³‡çµ„åˆé€²è¡Œå›æ¸¬ã€‚æ ¸å¿ƒç›®æ¨™æ˜¯ï¼š

1. **é æ¸¬è‚¡ç¥¨æœªä¾†å ±é…¬**ï¼šé æ¸¬æœªä¾† 5 æ—¥ï¼ˆå¯èª¿æ•´ï¼‰çš„è‚¡ç¥¨å ±é…¬ç‡
2. **å»ºæ§‹æŠ•è³‡çµ„åˆ**ï¼šæ ¹æ“šé æ¸¬çµæœé¸æ“‡ Top 10% çš„è‚¡ç¥¨
3. **å›æ¸¬é©—è­‰**ï¼šè©•ä¼°ç­–ç•¥çš„å¯¦éš›è¡¨ç¾ï¼Œèˆ‡ 0050 ETF åŸºæº–æ¯”è¼ƒ

---

## ğŸ“Š è³‡æ–™ç¯„åœ

- **æ™‚é–“ç¯„åœ**ï¼š2019 Q3 è‡³ 2025 Q3ï¼ˆç´„ 6 å¹´ï¼‰
- **è‚¡ç¥¨æ•¸é‡**ï¼š771 æª”å°ç£è‚¡ç¥¨
- **ç‰¹å¾µæ•¸é‡**ï¼š56 å€‹æŠ€è¡“æŒ‡æ¨™å’Œè²¡å‹™ç‰¹å¾µ
- **è³‡æ–™é »ç‡**ï¼šæ—¥é »

---

## ğŸ—ï¸ å°ˆæ¡ˆæ¶æ§‹

æœ¬å°ˆæ¡ˆåŒ…å«**å…©å¥—æ¨¡å‹å¯¦ä½œ**ï¼š

### 1. åŸå§‹ç‰ˆæœ¬ï¼ˆè¼ƒç°¡åŒ–ï¼‰

**æª”æ¡ˆï¼š** `train_gat_fixed.py`

**æ¨¡å‹é¡å‹ï¼š**
- **GATRegressor**ï¼šç°¡åŒ–ç‰ˆ GAT æ¨¡å‹ï¼ˆåƒ…ä½¿ç”¨ç”¢æ¥­åœ–ï¼‰
- **DMFM**ï¼šåˆç‰ˆæ·±åº¦å¤šå› å­æ¨¡å‹ï¼ˆéƒ¨åˆ†å°é½Šè«–æ–‡ï¼‰

**ç‰¹é»ï¼š**
- è³‡æ–™é è™•ç†ä½¿ç”¨æˆªé¢æ¨™æº–åŒ–ï¼ˆz-scoreï¼‰
- æ¨™ç±¤åšæˆªé¢å»å‡å€¼
- æå¤±å‡½æ•¸ï¼šcorr_mse_indï¼ˆåˆ†ç”¢æ¥­ç›¸é—œæ€§æå¤±ï¼‰

### 2. Wei et al. (2022) å®Œæ•´ç‰ˆæœ¬ï¼ˆæœ¬æ¬¡å¯¦ä½œï¼‰

**æª”æ¡ˆï¼š** `train_dmfm_wei2022.py`, `model_dmfm_wei2022.py`

**æ¨¡å‹é¡å‹ï¼š** DMFM_Wei2022ï¼ˆå®Œå…¨å°é½Šè«–æ–‡ï¼‰

**ç‰¹é»ï¼š**
- è³‡æ–™ä¿ç•™åŸå§‹å€¼ï¼ˆæ¨¡å‹å…§éƒ¨ä½¿ç”¨ BatchNormï¼‰
- éšå±¤å¼é›™åœ–çµæ§‹ï¼ˆç”¢æ¥­åœ– + å…¨å¸‚å ´åœ–ï¼‰
- ç”¢æ¥­ä¸­æ€§åŒ– + å…¨å¸‚å ´ä¸­æ€§åŒ–
- Factor Attention æ¨¡çµ„ï¼ˆå¯è§£é‡‹æ€§ï¼‰
- è«–æ–‡æå¤±å‡½æ•¸ï¼š`L = Î»_attnÂ·d + Î»_ICÂ·(1-IC) - b`

---

## ğŸ§  æ ¸å¿ƒæŠ€è¡“

### 1. åœ–æ³¨æ„åŠ›ç¶²è·¯ï¼ˆGATï¼‰

**ç‚ºä»€éº¼ç”¨åœ–ï¼Ÿ**
- è‚¡ç¥¨ä¹‹é–“æœ‰é—œè¯æ€§ï¼ˆåŒç”¢æ¥­ã€ä¾›æ‡‰éˆã€å¸‚å ´å…±æŒ¯ï¼‰
- GAT å¯ä»¥å­¸ç¿’è‚¡ç¥¨é–“çš„å½±éŸ¿é—œä¿‚

**å…©ç¨®åœ–çµæ§‹ï¼š**

#### ç”¢æ¥­åœ–ï¼ˆIndustry Graphï¼‰
- **ç¯€é»**ï¼šè‚¡ç¥¨
- **é‚Š**ï¼šåŒç”¢æ¥­çš„è‚¡ç¥¨äº’ç›¸é€£æ¥
- **ç›®çš„**ï¼šå­¸ç¿’ç”¢æ¥­å…§çš„å…±åŒå½±éŸ¿

**ç¯„ä¾‹ï¼š**
```
åŠå°é«”ç”¢æ¥­ï¼šå°ç©é›» â†” è¯ç™¼ç§‘ â†” æ—¥æœˆå…‰
é‡‘èç”¢æ¥­ï¼š  ä¸­ä¿¡é‡‘ â†” å¯Œé‚¦é‡‘ â†” ç‰å±±é‡‘
```

#### å…¨å¸‚å ´åœ–ï¼ˆUniverse Graphï¼‰
- **ç¯€é»**ï¼šè‚¡ç¥¨
- **é‚Š**ï¼šæ‰€æœ‰è‚¡ç¥¨äº’ç›¸é€£æ¥ï¼ˆå…¨é€£æ¥åœ–ï¼‰
- **ç›®çš„**ï¼šå­¸ç¿’è·¨ç”¢æ¥­çš„å¸‚å ´å…±åŒå½±éŸ¿

---

### 2. éšå±¤å¼ä¸­æ€§åŒ–ï¼ˆHierarchical Neutralizationï¼‰

é€™æ˜¯ Wei et al. (2022) è«–æ–‡çš„æ ¸å¿ƒå‰µæ–°ã€‚

#### æµç¨‹åœ–ï¼š

```
åŸå§‹ç‰¹å¾µ F^t [N, 56]
    â†“
[BatchNorm + MLP ç·¨ç¢¼]
    â†“
ç·¨ç¢¼ç‰¹å¾µ C^t [N, 64] â† ç¬¬ä¸€ç¨®ç‰¹å¾µï¼ˆåŒ…å«æ‰€æœ‰ä¿¡æ¯ï¼‰
    â†“
[GAT on ç”¢æ¥­åœ–] â†’ å­¸ç¿’ç”¢æ¥­å½±éŸ¿ H^t_I
    â†“
C^t - H^t_I = CÌ„^t_I [N, 64] â† ç¬¬äºŒç¨®ç‰¹å¾µï¼ˆç”¢æ¥­ä¸­æ€§åŒ–ï¼‰
    â†“
[GAT on å…¨å¸‚å ´åœ–] â†’ å­¸ç¿’å¸‚å ´å½±éŸ¿ H^t_U
    â†“
CÌ„^t_I - H^t_U = CÌ„^t_U [N, 64] â† ç¬¬ä¸‰ç¨®ç‰¹å¾µï¼ˆå…¨å¸‚å ´ä¸­æ€§åŒ–ï¼‰
    â†“
[æ‹¼æ¥ C^t || CÌ„^t_I || CÌ„^t_U] â†’ [N, 192]
    â†“
[MLP è§£ç¢¼å™¨]
    â†“
æ·±åº¦å› å­ f^t [N, 1] â†’ é æ¸¬å ±é…¬ç‡
```

#### é‡‘èæ„ç¾©ï¼š

**ç”¢æ¥­ä¸­æ€§åŒ–ï¼ˆC â†’ C_Iï¼‰**
```
ç¯„ä¾‹ï¼š
- æ•´å€‹åŠå°é«”ç”¢æ¥­éƒ½åœ¨æ¼² +5%ï¼ˆç”¢æ¥­æ•ˆæ‡‰ï¼‰
- å°ç©é›»æ¼² +8%
â†’ ç”¢æ¥­ä¸­æ€§åŒ–å¾Œä¿ç•™ +3%ï¼ˆè¶…é¡éƒ¨åˆ†ï¼‰
```

**å…¨å¸‚å ´ä¸­æ€§åŒ–ï¼ˆC_I â†’ C_Uï¼‰**
```
ç¯„ä¾‹ï¼š
- å…¨å¸‚å ´ï¼ˆå¤§ç›¤ï¼‰éƒ½åœ¨æ¼² +2%ï¼ˆå¸‚å ´æ•ˆæ‡‰ï¼‰
- å°ç©é›»ï¼ˆç”¢æ¥­ä¸­æ€§åŒ–å¾Œï¼‰æ¼² +3%
â†’ å…¨å¸‚å ´ä¸­æ€§åŒ–å¾Œä¿ç•™ +1%ï¼ˆç´”å€‹è‚¡æ•ˆæ‡‰ï¼‰
```

**ä¸‰ç¨®ç‰¹å¾µçš„æ„ç¾©ï¼š**
- **C**ï¼šåŸå§‹ç·¨ç¢¼ç‰¹å¾µï¼ˆå¸‚å ´ + ç”¢æ¥­ + å€‹è‚¡ï¼‰
- **C_I**ï¼šç”¢æ¥­ä¸­æ€§ç‰¹å¾µï¼ˆå¸‚å ´ + å€‹è‚¡ï¼‰
- **C_U**ï¼šå…¨å¸‚å ´ä¸­æ€§ç‰¹å¾µï¼ˆç´”å€‹è‚¡ï¼‰

æ‹¼æ¥ä¸‰ç¨®ç‰¹å¾µï¼Œè®“æ¨¡å‹åŒæ™‚å­¸ç¿’ä¸åŒå±¤æ¬¡çš„ä¿¡æ¯ï¼

---

### 3. Factor Attention æ¨¡çµ„ï¼ˆå¯è§£é‡‹æ€§ï¼‰

**å•é¡Œï¼š** æ·±åº¦å­¸ç¿’æ¨¡å‹æ˜¯é»‘ç®±ï¼Œæˆ‘å€‘ä¸çŸ¥é“å®ƒç‚ºä»€éº¼é æ¸¬æŸå€‹è‚¡ç¥¨æœƒæ¼²ã€‚

**è§£æ±ºæ–¹æ¡ˆï¼š** Factor Attention æ¨¡çµ„

#### é‹ä½œæ–¹å¼ï¼š

```python
# å­¸ç¿’æ¯å€‹ç‰¹å¾µçš„é‡è¦æ€§æ¬Šé‡
U = LeakyReLU(W Â· F)  # [N, 56]
A = Softmax(U)        # [N, 56] æ­¸ä¸€åŒ–ç‚ºæ¬Šé‡

# ç”¨æ³¨æ„åŠ›æ¬Šé‡ä¼°è¨ˆå› å­
f_hat = F^T Â· A       # [N, 1]

# æå¤±å‡½æ•¸ï¼šæœ€å°åŒ–æ·±åº¦å› å­èˆ‡æ³¨æ„åŠ›ä¼°è¨ˆçš„å·®ç•°
d = ||f - f_hat||Â²
```

#### æ‡‰ç”¨ï¼š

è¦–è¦ºåŒ–å¾Œå¯ä»¥çœ‹åˆ°ï¼š
- **å“ªäº›æŠ€è¡“æŒ‡æ¨™æœ€é‡è¦**ï¼ˆå¦‚ RSIã€MACDã€å‹•é‡ï¼‰
- **æ¬Šé‡éš¨æ™‚é–“çš„è®ŠåŒ–**ï¼ˆå¸‚å ´ä¸åŒéšæ®µï¼Œé‡è¦ç‰¹å¾µä¸åŒï¼‰
- **Top 10 ç‰¹å¾µé€šå¸¸ä½”ç¸½æ¬Šé‡ 40-60%**

**ç¯„ä¾‹è¼¸å‡ºï¼š**
```
Top 10 Most Important Features:
  1. ret_10        : 0.0853 (è¿‘ 10 æ—¥å ±é…¬)
  2. ret_20        : 0.0721 (è¿‘ 20 æ—¥å ±é…¬)
  3. rsi_14        : 0.0612 (RSI æŒ‡æ¨™)
  4. px_over_sma_20: 0.0543 (åƒ¹æ ¼ç›¸å°å‡ç·š)
  5. macd          : 0.0489 (MACD æŒ‡æ¨™)
  ...
```

---

## ğŸ“ˆ ç‰¹å¾µå·¥ç¨‹ï¼ˆ56 å€‹ç‰¹å¾µï¼‰

### å‹•é‡é¡ï¼ˆ9 å€‹ï¼‰
- `ret_1, ret_3, ret_5, ret_10, ret_20`ï¼šä¸åŒæœŸé–“çš„å ±é…¬ç‡
- `mom_diff_10, mom_diff_20`ï¼šå‹•èƒ½å·®ï¼ˆçŸ­æœŸ - é•·æœŸï¼‰
- `rev_1, rev_5, rev_10`ï¼šåè½‰æ•ˆæ‡‰

### ç§»å‹•å¹³å‡ï¼ˆ4 å€‹ï¼‰
- `px_over_sma_5, px_over_sma_10, px_over_sma_20, px_over_sma_60`ï¼šåƒ¹æ ¼ç›¸å°å‡ç·š

### æ³¢å‹•ç‡ï¼ˆ4 å€‹ï¼‰
- `std_ret_5, std_ret_10, std_ret_20, std_ret_60`ï¼šå ±é…¬æ¨™æº–å·®
- `atr_14`ï¼šATRï¼ˆçœŸå¯¦æ³¢å¹…ï¼‰
- `idio_vol_60`ï¼šå€‹è‚¡æ³¢å‹•ï¼ˆå»é™¤å¸‚å ´æ³¢å‹•ï¼‰

### æˆäº¤é‡ï¼ˆ4 å€‹ï¼‰
- `vol_over_ma_5, vol_over_ma_10, vol_over_ma_20, vol_over_ma_60`ï¼šé‡èƒ½ç›¸å°å‡å€¼

### æŠ€è¡“æŒ‡æ¨™ï¼ˆ6 å€‹ï¼‰
- `rsi_14`ï¼šRSI æŒ‡æ¨™
- `stoch_k_14, stoch_d_3`ï¼šKD æŒ‡æ¨™
- `macd, macd_signal, macd_hist`ï¼šMACD æŒ‡æ¨™

### çµ±è¨ˆç‰¹æ€§ï¼ˆ5 å€‹ï¼‰
- `skew_20, kurt_20`ï¼šååº¦èˆ‡å³°åº¦
- `zscore_close_20, zscore_close_60`ï¼šåƒ¹æ ¼ z-score
- `beta_60`ï¼šBeta ä¿‚æ•¸

### åƒ¹ä½ç›¸é—œï¼ˆ12 å€‹ï¼‰
- `roll_max_5, roll_max_10, roll_max_20, roll_max_60`ï¼šæ»¾å‹•æœ€é«˜åƒ¹
- `roll_min_5, roll_min_10, roll_min_20, roll_min_60`ï¼šæ»¾å‹•æœ€ä½åƒ¹
- `pct_pos_5, pct_pos_10, pct_pos_20, pct_pos_60`ï¼šé™½ç·šæ¯”ä¾‹
- `pct_to_high_20, pct_to_low_20`ï¼šç›¸å°é«˜ä½é»ä½ç½®
- `mdd_20`ï¼šæœ€å¤§å›æ’¤

### æµå‹•æ€§ï¼ˆ2 å€‹ï¼‰
- `amihud_5, amihud_20`ï¼šAmihud éæµå‹•æ€§æŒ‡æ¨™

### ä¼°å€¼ï¼ˆ2 å€‹ï¼‰
- `pb, ps`ï¼šæœ¬ç›Šæ¯”ã€è‚¡åƒ¹ç‡Ÿæ”¶æ¯”

---

## ğŸ“ è©•ä¼°æŒ‡æ¨™

### 1. IC (Information Coefficient)

**å®šç¾©ï¼š** é æ¸¬å€¼èˆ‡çœŸå¯¦å ±é…¬çš„ Pearson ç›¸é—œä¿‚æ•¸

**å…¬å¼ï¼š**
```
IC = Corr(é æ¸¬å ±é…¬, çœŸå¯¦å ±é…¬)
```

**è§£è®€ï¼š**
- IC > 0.05ï¼šå¯äº¤æ˜“æ°´æº–
- IC > 0.10ï¼šå„ªç§€æ°´æº–
- IC < 0ï¼šé æ¸¬æ–¹å‘éŒ¯èª¤

**ç›®å‰çµæœï¼š**
```
åŸå§‹ GATRegressor:
  æ¸¬è©¦é›† IC: 0.0192 (åå¼±)

é æœŸ DMFM_Wei2022:
  æ¸¬è©¦é›† IC: 0.03 - 0.08 (å¯ç”¨)
```

---

### 2. ICIR (IC Information Ratio)

**å®šç¾©ï¼š** IC çš„ç©©å®šæ€§

**å…¬å¼ï¼š**
```
ICIR = Mean(IC) / Std(IC)
```

**è§£è®€ï¼š**
- ICIR > 0.5ï¼šç©©å®š
- ICIR > 1.0ï¼šè¡¨ç¾æ¥µä½³
- ICIR < 0ï¼šä¸ç©©å®š

**ç›®å‰çµæœï¼š**
```
åŸå§‹ GATRegressor:
  æ¸¬è©¦é›† ICIR: 0.0827 (åå¼±)

é æœŸ DMFM_Wei2022:
  æ¸¬è©¦é›† ICIR: 0.5 - 1.5 (ç©©å®š)
```

---

### 3. Dir Accuracy (æ–¹å‘æº–ç¢ºç‡)

**å®šç¾©ï¼š** é æ¸¬æ¼²è·Œæ–¹å‘çš„æº–ç¢ºç‡

**å…¬å¼ï¼š**
```
Dir Acc = % of (sign(é æ¸¬) == sign(çœŸå¯¦))
```

**è§£è®€ï¼š**
- 50%ï¼šéš¨æ©ŸçŒœæ¸¬
- > 55%ï¼šå…·å¯¦ç”¨åƒ¹å€¼
- > 60%ï¼šå„ªç§€

**ç›®å‰çµæœï¼š**
```
åŸå§‹ GATRegressor:
  æ¸¬è©¦é›† Dir Acc: 48.48% (ä¸ä½³)
```

---

### 4. Factor Return (å› å­æ”¶ç›Š)

**å®šç¾©ï¼š** æ·±åº¦å› å­å°å ±é…¬çš„è§£é‡‹èƒ½åŠ›

**è¨ˆç®—ï¼š** Cross-sectional regression
```
r^t = b^t Â· f^t + Îµ
```

**è§£è®€ï¼š**
- b > 0ï¼šå› å­èˆ‡å ±é…¬æ­£ç›¸é—œ
- Cumulative bï¼šç´¯ç©å› å­æ”¶ç›Š

---

## ğŸ”¬ å¯¦é©—è¨­å®š

### è³‡æ–™åˆ‡åˆ†

```
ç¸½è³‡æ–™ï¼š619 å¤©ï¼ˆ2019-09-16 ~ 2025-09-12ï¼‰
è¨“ç·´é›†ï¼š495 å¤©ï¼ˆ80%ï¼‰
æ¸¬è©¦é›†ï¼š124 å¤©ï¼ˆ20%ï¼‰
```

### æ¨¡å‹åƒæ•¸

```python
æ¨¡å‹ï¼šDMFM_Wei2022
  - num_features: 56
  - hidden_dim: 64
  - heads: 2
  - dropout: 0.1
  - å¯è¨“ç·´åƒæ•¸: 48,297

è¨“ç·´ï¼š
  - epochs: 200
  - learning_rate: 1e-3
  - optimizer: AdamW
  - weight_decay: 0.01
  - patience: 30 (early stopping)

æå¤±å‡½æ•¸ï¼š
  - lambda_attn: 0.1
  - lambda_ic: 1.0
```

---

## ğŸ“ å°ˆæ¡ˆæª”æ¡ˆçµæ§‹

```
gat_9_15/
â”œâ”€â”€ è³‡æ–™èˆ‡æ¨¡å‹è…³æœ¬
â”‚   â”œâ”€â”€ build_artifacts.py
â”‚   â”œâ”€â”€ train_dmfm_wei2022.py
â”‚   â”œâ”€â”€ train_gat_fixed.py
â”‚   â”œâ”€â”€ train_baselines.py
â”‚   â”œâ”€â”€ model_dmfm_wei2022.py
â”‚   â””â”€â”€ evaluate_* / plot_* / visualize_* / analyze_* ç³»åˆ—
â”‚
â”œâ”€â”€ åŸ·è¡Œè…³æœ¬
â”‚   â””â”€â”€ run_core_experiments.sh
â”‚
â”œâ”€â”€ ç¯„ä¾‹è¼¸å‡º (examples/)
â”‚   â”œâ”€â”€ artifacts/{covid_crash,rate_hike}/
â”‚   â””â”€â”€ plots/
â”‚       â”œâ”€â”€ short|medium|long/{dmfm,gat}/
â”‚       â””â”€â”€ covid_crash|rate_hike/{dmfm,gat}/
â”‚
â”œâ”€â”€ æ­¸æª”è…³æœ¬ (archived/)
â”‚   â”œâ”€â”€ run_dmfm_wei2022.sh
â”‚   â”œâ”€â”€ run_experiments.sh
â”‚   â””â”€â”€ run_all_models_parallel.sh
â”‚
â””â”€â”€ èªªæ˜æ–‡ä»¶
    â”œâ”€â”€ README.md, QUICK_START.md
    â”œâ”€â”€ README_DMFM_Wei2022.md
    â”œâ”€â”€ CHANGES_DMFM_Wei2022.md
    â”œâ”€â”€ RUNPODS_GUIDE.md
    â””â”€â”€ VENV_SETUP.md / HIERARCHICAL_NEUTRALIZATION_EXPLAINED.md
```

---

## ğŸš€ å®Œæ•´åŸ·è¡Œæµç¨‹

### Step 1: è³‡æ–™é è™•ç†

```bash
python build_artifacts.py \
  --prices unique_2019q3to2025q3.csv \
  --industry_csv unique_2019q3to2025q3.csv \
  --artifact_dir gat_artifacts_out_wei2022 \
  --start_date 2019-09-16 \
  --end_date 2025-09-12 \
  --horizon 5
```

**è¼¸å‡ºï¼š**
- `Ft_tensor.pt`ï¼šç‰¹å¾µå¼µé‡ [619, 771, 56]
- `yt_tensor.pt`ï¼šæ¨™ç±¤å¼µé‡ [619, 771]
- `industry_edge_index.pt`ï¼šç”¢æ¥­åœ– [2, 27923]
- `universe_edge_index.pt`ï¼šå…¨å¸‚å ´åœ– [2, 594441]

---

### Step 2: è¨“ç·´æ¨¡å‹

```bash
python train_dmfm_wei2022.py \
  --artifact_dir gat_artifacts_out_wei2022 \
  --epochs 200 \
  --lr 1e-3 \
  --device cuda \
  --patience 30
```

**è¨“ç·´éç¨‹ï¼š**
```
Epoch   5 | Train Loss: 1.2345 | Train IC: 0.0234 | Test IC: 0.0412 | Test ICIR: 0.3421 | Test FR: 0.0123
Epoch  10 | Train Loss: 0.9876 | Train IC: 0.0345 | Test IC: 0.0523 | Test ICIR: 0.5234 | Test FR: 0.0234
...
Epoch  50 | Train Loss: 0.5432 | Train IC: 0.0567 | Test IC: 0.0634 | Test ICIR: 0.8765 | Test FR: 0.0456
```

**è¼¸å‡ºï¼š**
- `dmfm_wei2022_best.pt`ï¼šæœ€ä½³æ¨¡å‹
- `train_log_wei2022.txt`ï¼šè¨“ç·´æ—¥èªŒ

---

### Step 3: è¦–è¦ºåŒ– Factor Attention

```bash
python visualize_factor_attention.py \
  --artifact_dir gat_artifacts_out_wei2022 \
  --output_dir plots_attention_wei2022
```

**è¼¸å‡ºåœ–è¡¨ï¼š**
1. Top 15 ç‰¹å¾µé‡è¦æ€§
2. æ‰€æœ‰ç‰¹å¾µæ’åº
3. Top 5 ç‰¹å¾µæ™‚é–“åºåˆ—
4. Top 20 ç‰¹å¾µç†±åŠ›åœ–
5. ç‰¹å¾µé‡è¦æ€§é¤…åœ–

---

### Step 4: åˆ†æéšå±¤å¼ç‰¹å¾µ

```bash
python analyze_contexts.py \
  --artifact_dir gat_artifacts_out_wei2022 \
  --output_dir plots_contexts_wei2022
```

**åˆ†æå…§å®¹ï¼š**
- è®Šç•°æ•¸é™ä½æ•ˆæœ
- ç”¢æ¥­å½±éŸ¿ vs å…¨å¸‚å ´å½±éŸ¿
- PCA 2D æŠ•å½±

---

### Step 5: è©•ä¼°æŒ‡æ¨™

```bash
python evaluate_metrics.py \
  --artifact_dir gat_artifacts_out_wei2022 \
  --weights gat_artifacts_out_wei2022/dmfm_wei2022_best.pt
```

**è¼¸å‡ºæŒ‡æ¨™ï¼š**
- IC, ICIR, Dir Accuracy
- MSE, MAE, RMSE

---

### Step 6: æŠ•è³‡çµ„åˆå›æ¸¬

```bash
python evaluate_portfolio.py \
  --artifact_dir gat_artifacts_out_wei2022 \
  --weights gat_artifacts_out_wei2022/dmfm_wei2022_best.pt \
  --top_pct 0.10 \
  --rebalance_days 5
```

**å›æ¸¬é‚è¼¯ï¼š**
1. æ¯ 5 å¤©èª¿æ•´ä¸€æ¬¡æŒè‚¡
2. é¸æ“‡é æ¸¬å ±é…¬ Top 10% çš„è‚¡ç¥¨
3. ç­‰æ¬Šé‡é…ç½®
4. è¨ˆç®—ç´¯ç©å ±é…¬ã€å¤æ™®æ¯”ç‡ã€æœ€å¤§å›æ’¤

---

## ğŸ’¡ ç ”ç©¶å•é¡Œ

### 1. ç‚ºä»€éº¼åŸå§‹ GATRegressor è¡¨ç¾ä¸ä½³ï¼Ÿ

**å¯èƒ½åŸå› ï¼š**
- åƒ…ä½¿ç”¨ç”¢æ¥­åœ–ï¼Œæœªè€ƒæ…®å…¨å¸‚å ´å½±éŸ¿
- æå¤±å‡½æ•¸éæ–¼ç°¡åŒ–
- ç¼ºä¹å¯è§£é‡‹æ€§ï¼ˆç„¡æ³•è¨ºæ–·å•é¡Œï¼‰

**è§£æ±ºæ–¹æ¡ˆï¼š** DMFM_Wei2022
- éšå±¤å¼é›™åœ–çµæ§‹
- è«–æ–‡æå¤±å‡½æ•¸ï¼ˆd - b + ICï¼‰
- Factor Attention æ¨¡çµ„

---

### 2. ç”¢æ¥­ä¸­æ€§åŒ–å’Œå…¨å¸‚å ´ä¸­æ€§åŒ–çš„æ•ˆæœå¦‚ä½•ï¼Ÿ

**é æœŸï¼š**
- è®Šç•°æ•¸é™ä½ 15-40%
- æ›´å¥½çš„æ³›åŒ–èƒ½åŠ›
- æ¸›å°‘éæ“¬åˆ

**é©—è­‰æ–¹å¼ï¼š**
```bash
python analyze_contexts.py
cat plots_contexts_wei2022/context_analysis_summary.txt
```

---

### 3. å“ªäº›ç‰¹å¾µå°é æ¸¬æœ€é‡è¦ï¼Ÿ

**é æœŸï¼š**
- å‹•é‡é¡ï¼ˆret_10, ret_20ï¼‰
- æŠ€è¡“æŒ‡æ¨™ï¼ˆRSI, MACDï¼‰
- ç›¸å°å¼·åº¦ï¼ˆpx_over_smaï¼‰

**é©—è­‰æ–¹å¼ï¼š**
```bash
python visualize_factor_attention.py
cat plots_attention_wei2022/factor_attention_summary.txt
```

---

## ğŸ¯ æœªä¾†æ–¹å‘

### çŸ­æœŸï¼ˆ1-2 é€±ï¼‰

1. **å®Œæˆ DMFM_Wei2022 è¨“ç·´**
   - ä¿®å¾© dtype å•é¡Œå¾Œé‡æ–°è¨“ç·´
   - è©•ä¼° IC, ICIR æŒ‡æ¨™
   - èˆ‡åŸå§‹ç‰ˆæœ¬æ¯”è¼ƒ

2. **è¦–è¦ºåŒ–åˆ†æ**
   - Factor Attention æ¬Šé‡
   - éšå±¤å¼ç‰¹å¾µæ•ˆæœ
   - èˆ‡ 0050 æ¯”è¼ƒ

---

### ä¸­æœŸï¼ˆ1-2 æœˆï¼‰

1. **æ¨¡å‹å„ªåŒ–**
   - è¶…åƒæ•¸èª¿å„ªï¼ˆhidden_dim, heads, dropoutï¼‰
   - ä¸åŒæå¤±å‡½æ•¸æ¬Šé‡ï¼ˆlambda_attn, lambda_icï¼‰
   - Ensemble å¤šå€‹æ¨¡å‹

2. **ç‰¹å¾µå·¥ç¨‹**
   - æ–°å¢åŸºæœ¬é¢ç‰¹å¾µï¼ˆè²¡å ±æ•¸æ“šï¼‰
   - æ–°å¢æƒ…ç·’æŒ‡æ¨™ï¼ˆæ–°èã€ç¤¾ç¾¤ï¼‰
   - ç‰¹å¾µé¸æ“‡ï¼ˆç§»é™¤å†—é¤˜ç‰¹å¾µï¼‰

3. **æŠ•è³‡çµ„åˆå„ªåŒ–**
   - é¢¨éšªæ§åˆ¶ï¼ˆæ³¢å‹•ç‡ç›®æ¨™ã€VaRï¼‰
   - äº¤æ˜“æˆæœ¬æ¨¡æ“¬ï¼ˆæ‰‹çºŒè²»ã€æ»‘åƒ¹ï¼‰
   - å¤šç©ºç­–ç•¥

---

### é•·æœŸï¼ˆ3-6 æœˆï¼‰

1. **é€²éšæ¨¡å‹**
   - Temporal GATï¼ˆè€ƒæ…®æ™‚é–“åºåˆ—ï¼‰
   - Multi-task Learningï¼ˆåŒæ™‚é æ¸¬å ±é…¬ã€æ³¢å‹•ã€é¢¨éšªï¼‰
   - Reinforcement Learningï¼ˆç›´æ¥å„ªåŒ–æŠ•è³‡çµ„åˆï¼‰

2. **å¯¦ç›¤æ¸¬è©¦**
   - ç´™ä¸Šäº¤æ˜“ï¼ˆPaper Tradingï¼‰
   - å°è³‡é‡‘å¯¦æ¸¬
   - é¢¨éšªç›£æ§

---

## ğŸ“š åƒè€ƒæ–‡ç»

### æ ¸å¿ƒè«–æ–‡

1. **Wei, L., Li, B., & Chen, Y. (2022).** Deep Multi-Factor Model for Stock Prediction.
   - æœ¬å°ˆæ¡ˆçš„ä¸»è¦åƒè€ƒè«–æ–‡
   - æå‡ºéšå±¤å¼ä¸­æ€§åŒ–ã€Factor Attention

2. **VeliÄkoviÄ‡, P., et al. (2018).** Graph Attention Networks.
   - GAT çš„åŸå§‹è«–æ–‡
   - æ³¨æ„åŠ›æ©Ÿåˆ¶åœ¨åœ–ä¸Šçš„æ‡‰ç”¨

### ç›¸é—œæŠ€è¡“

3. **Ioffe, S., & Szegedy, C. (2015).** Batch Normalization.
   - BatchNorm çš„ç†è«–åŸºç¤

4. **He, K., et al. (2016).** Deep Residual Learning.
   - Residual Connectionï¼ˆæœªä¾†å¯å˜—è©¦ï¼‰

---

## ğŸ‘¤ ä½œè€…

**Lo Yi (ç¾…é ¤)**
National Yang Ming Chiao Tung University
Graduate Institute of Information Management & Finance
E-mail: roy60404@gmail.com

---

## ğŸ“ ç‰ˆæœ¬è¨˜éŒ„

- **v1.0.0** (2025-01-XX): åˆå§‹ç‰ˆæœ¬ï¼ŒGATRegressor + åˆç‰ˆ DMFM
- **v2.0.0** (2025-01-XX): å®Œæ•´å¯¦ä½œ DMFM_Wei2022ï¼Œå°é½Šè«–æ–‡æ¶æ§‹
